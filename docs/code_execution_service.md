# Code Execution Service

The Code Execution Service is a microservice responsible for safely executing Python code generated by the LLM Service. It provides a secure sandbox environment for running data analysis code against the music dataset.

## Overview

The Code Execution Service is implemented as a FastAPI application that:

1. Receives Python code from the Streamlit frontend
2. Validates the code for security issues
3. Executes the code in a restricted environment
4. Captures output, errors, and visualizations
5. Returns the results to the frontend

## Security Features

The service implements multiple layers of security to prevent malicious code execution:

1. **Code Validation**: Uses `validate_generated_code()` from `llm_utils` to check for forbidden patterns
2. **RestrictedPython**: Executes code in a restricted environment with limited access to Python features
3. **Custom Importer**: Restricts which modules can be imported
4. **Allowlisted Modules**: Only allows specific, safe modules (pandas, numpy, matplotlib, etc.)
5. **No File System Access**: Prevents reading or writing files
6. **No Network Access**: Blocks all network-related operations
7. **No System Commands**: Prevents execution of system commands

## API Endpoints

### POST `/api/execute`

Executes Python code safely and returns the results.

- **Request Body**:
  ```json
  {
    "code": "# Python code to execute"
  }
  ```

- **Response**:
  ```json
  {
    "success": true,
    "output": "Text output from code execution",
    "has_visualization": true,
    "visualization": "base64-encoded PNG image",
    "error": null,
    "traceback": null
  }
  ```

### GET `/api/health`

Health check endpoint to verify the service is running and data is loaded.

- **Response**:
  ```json
  {
    "status": "healthy",
    "service": "code-execution-service",
    "data_loaded": true,
    "row_count": 10000
  }
  ```

## Data Models

### `CodeRequest`

Pydantic model for code execution requests:
- `code`: The Python code to execute

### `ExecutionResponse`

Pydantic model for execution results:
- `success`: Boolean indicating if execution was successful
- `output`: Text output from code execution
- `has_visualization`: Boolean indicating if a visualization was generated
- `visualization`: Base64-encoded PNG image (if visualization was generated)
- `error`: Error message (if execution failed)
- `traceback`: Python traceback (if execution failed)

## Restricted Execution Environment

The service creates a restricted execution environment with:

1. **Limited Builtins**: Only safe Python builtins are available
2. **Pre-imported Modules**: Safe modules are pre-imported and added to the globals
3. **Custom Guards**: Special guards for iteration, attribute access, and item access
4. **Print Collector**: Captures print output instead of writing to stdout
5. **Visualization Capture**: Automatically captures matplotlib visualizations as base64-encoded images

## Visualization Handling

The service includes special handling for matplotlib visualizations:

1. Automatically detects if code generates a plot
2. Captures the plot as a PNG image in a BytesIO buffer
3. Encodes the image as base64 for transmission to the frontend
4. Closes all matplotlib figures to prevent memory leaks

## Service Initialization

The service initializes on startup by:

1. Loading environment variables
2. Setting up logging
3. Loading the music dataset into memory

The dataset is loaded once at startup and kept in memory for all subsequent requests, improving performance.

## Configuration

The service is configured through environment variables:

- `CODE_EXECUTION_SERVICE_PORT`: Port to run the service on (default: 8082)
- Environment variables for data loading (inherited from data_utils.py)

## Docker Configuration

The service runs in a Docker container with:
- Python 3.12 base image
- Access to shared modules (data_utils.py, llm_utils.py)
- Access to the data directory
- Port 8082 exposed

## Error Handling

The service includes comprehensive error handling:
- Code validation errors
- Syntax errors in the code
- Runtime errors during execution
- Memory or resource limit errors

All errors are caught, logged, and returned in a structured format.

## Integration with Other Services

The Code Execution Service is designed to work with:
- The Streamlit frontend, which sends code and displays results

It does not directly interact with the LLM Service; that integration is handled by the Streamlit app.
